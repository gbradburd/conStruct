%%%%%%
%%
%%  Don't reorder the reviewer points; that'll mess up the automatic referencing!
%%
%%%%%

% to-do: get letterhead back in somehow? or not.
% \usepackage[green]{msuletterhead}

\begin{minipage}[b]{2.5in}
  Resubmission Cover Letter \\
    {\it Genetics} 
\end{minipage}
\hfill
\begin{minipage}[b]{2.5in}
  \today
\end{minipage}
 
\vskip 2em
 
\noindent


To the Editor,

Please find enclosed the re-submission of our manuscript, 
``Inferring Continuous and Discrete Population Genetic Structure Across Space,"
for re-consideration for publication in Genetics.

We appreciate the opportunity to submit a revised version of the manuscript.  
The comments provided by the Editor 
and the anonymous reviewers are very helpful, 
and we believe the manuscript is improved as a result 
of their critiques.

Our detailed responses to those comments are inset below,
but, in brief, we have included more of the results of the ADMIXTURE analyses 
in the main body of the text.
Specifically, we have added figure panels to Figures 7 and 8 
that explicitly compare \texttt{conStruct}'s results with those of ADMIXTURE 
on the black bear dataset.
We have also added text throughout the results to increase the depth of 
our comparison of \texttt{conStruct} and ADMIXTURE, 
and generally edited the manuscript for greater clarity.

We hope that the paper is now acceptable for publication.


\noindent \hspace{4em}
\begin{minipage}{3in}
\noindent
    {\bf Thank you for your consideration,}

\vskip 2em

{\bf 
    Gideon Bradburd (for all of the authors)
}\\
\end{minipage}

\vskip 4em

\pagebreak



\newpage

%%%%%%%%%%%%%%
\reviewersection{Editor}

\begin{quote}
    We received the previous reviews for your paper, and sent also sent it out
    to a new reviewer, along with your response to the earlier reviews. Both the
    new reviewer and I believe that you have answered the previous criticisms in a
    reasonable way, and I am pleased to tell you that your paper is potentially
    suitable for publication in GENETICS. However, the new reviewer did have
    several comments which you should consider in preparing the final version (see
    the end of this email). In particular, they suggest including more of the
    ADMIXTURE models in the main text. I think that this could be helpful, but
    would not insist on it.  A second review came in late (attached).  I am sending
    it on in case you would like to take account of any of the suggestions in your
    revision. The reviewer has quite a few technical suggestions that may be
    helpful.  However, even if it had come in before the decision, I would not have
    required a wider range of simulations.  
\end{quote}

Thanks for the thoughtful consideration.
We agree in principle with the reviewer that more detailed tests of a method are always useful,
but, as discussed below, decided that the paper would be better served without additional simulations.
We hope that you agree.

%%%%%%%%%%%%%%
\reviewersection{1}

\begin{point}{}
    This manuscript presents a valuable model that addresses an long standing chestnut in population genetic analysis, which is how to jointly analyze discrete and spatially continuous variation within a single dataset.  The method presented does seem to be something of a breakthrough in addressing this problem sensibly.  I found the authors response to previous reviewer comments to be generally reasonable. However, I do think that there is a strong case for putting some more ADMIXTURE model results into the text and possibly for some additional analyses.
\end{point}

\reply{We have now added some of the ADMIXTURE results to the main text, 
including the admixture pie plot and the cross-validation results from the ADMIXTURE analyses 
of the bear dataset in Figures 7 and 8, respectively. 
We have also included more detailed comparisons between ADMIXTURE and \texttt{conStruct},
for instance at \llname{ll:admixture_sim_results} and \llname{ll:admixture_sim_xval};
see below for more.}

\begin{point}{}
    I agree with the authors point in their letter that ADMIXTURE/STRUCTURE is important because it is what almost everyone would do otherwise.  The key goal for the manuscript is to show that the method that everyone uses gives results that can be misleading/unhelpful and that the layered model is a substantial improvement. This is very clear for the simulated data. The previous reviewers are right to ask for additional simulations in the sense that a more biological simulation would make a stronger case for practical utility and it need not lengthen the manuscript significantly, since the current simulations could be largely relegated to supplementary material as representing ``simulation according to the model". But this is definitely an optional, since there are presentational arguments to be made either way.
\end{point}

\reply{
    We agree that more simulations would be nice,
    but after serious consideration, have decided it would be too far outside the scope
    of the already lengthy manuscript.
    The existing simulations are not quite ``according to the model'' --
    that would be simulations where we draw sample frequencies directly from a multivariate Gaussian
    (which is something we have done as a sanity check, but have not included).
    We feel that the existing simulations draw a nice compromise between realism
    and being close enough to the model that we still have a good idea of what the correct answer is.
    We do have plans to follow up with a more detailed simulation study.
}

\begin{point}{}
    A more biological simulation is not necessary as long as the real data examples are convincing. For the Poplar data, the key insight of the model is that there are three well-supported layers in addition to isolation by distance. This is not clear according to ADMIXTURE, which gives continuous improvement for K, although the clustering itself is reasonable. The differences in patterns of IBD between populations are also interesting.  For the bear data, there is a stronger case to be made, namely that as well as estimating a biologically insightful number of layers, individual ADMIXTURE or non-spatial model components are positively misleading for K=3 or more. For the Poplar example, the results are not actively misleading , they just represent finer and finer geography. The misleadingness of the bear results can be shown by the fact that although the cross validation shows continuous improvement, the admixture components are highly inconsistent between runs. For example at K=3, a component is shown that is shared between East and West, which if interpreted literally would represent a biologically important result about connections between populations but the clustering of the yellow populations disappears entirely for K=4. Therefore, I think there is a good case to be made for showing the ADMIXTURE model results in the text and to discuss the misleading/ unstable nature of any particular result.
\end{point}

\reply{We have added more extensive discussions of the 
comparison between \texttt{conStruct} and ADMIXTURE for both empirical datasets along these lines,
following \llname{ll:admixture_populus} and \llname{ll:admixture_bears}.
}

\begin{point}{}
    It would be interesting to do some kind of plot for ADMIXTURE results, to demonstrate that populations that share affinity according higher components are not particularly similar when allowing for geographical distance. This would be a rather direct way of showing that the ADMIXTURE model is not producing insightful results, despite the continuous improvement in model probability for higher K. In this context, I always think of the ``clines vs clusters" paper by Rosenberg. It would be great to have some kind of figure to show that for K=2, it looks like clusters but for K=3, the clusters add much less.
\end{point}

\reply{
    This is a good suggestion;
    we think we can make this point (and a related one) by looking at the covariance-versus distance
    plots for the bear data.
    The additional discussion of this point is at \revref,
    and a new figure showing covariances colored by population is at \ref{bear_cov_colorized};
    we decided not to insert yet another figure in the main text, however,
    and tried to describe the pattern verbally.
}

\begin{point}{}
    The layer specific covariances show a very funny pattern, tending to infinity for low distances for components 3 and above for the bear data. I am not sure I understand this. Is this discussed anywhere?
\end{point}

\reply{We think what's happening is that these layer-specific covariances for layers $>$2 
are describing local departures from global patterns of IBD, 
as might be expected due to, e.g., inbreeding.
We have added some text to that effect. \revref}

\begin{point}{}
    Minor point, in figure 4, legend, should it read in each run of the spatial model, rather than nonspatial model?
\end{point}

\reply{Good catch!  Caption has been fixed.}


%%%%%%%%%%%%%%
\reviewersection{2}

First, we want to thank Reviewer 2 for their very thorough  review
(even taking the time to check out the R package!).  
We really appreciate the time and thought the reviewer invested here.

\begin{point}{}
    Make-or-Break:
Ideally one tests a new method on simulated data, to assess its power -
and importantly whether everything was implemented correctly.
Here, there are simulations of one scenario, but it is neither strictly under-the-model 
nor a biologically plausible scenario (layers that coexist independent of each other are hard to imagine.
There seems to be a good fit for the ground-truth admixture coefficients in the scenario you simulate. 
However, you never assess how well you can fit isolation by distance parameters, 
and whether your posterior distribution makes any sense. 
This is a very important step in demonstrating that you implementation works - 
and would give me and other users much needed reassurance.
The authors also never give details such as migration rates of this simulations, 
so the reader has effectively no idea what the extend of isolation by distance and differentiation is in these simulations. 
Please put them at least in a supplement table. 
In general it is really hard to get a sense for the power of the method, 
as there is no exploration done in that direction. 
Power will obviously depend on a plethora of factors, 
but at least give an idea of what marker numbers you envision as typical input.
Given the high-dimensional parameter space there is no realistic way to thoroughly test your inference scheme in this paper - 
so I would be satisfied if you pick a set of parameters you deem realistic 
(for instance similar to the ones you estimate in the applications), 
and show that the inference method can infer them when simulated under the model. 
In particular, show that your model infers also the isolation by distance parameters well, 
and that the posteriors make sense. 
In case it does not (due to model degeneracies or similar issues , see below), 
it is not big deal as long as the ``important" admixture parameters are unaffected, 
but then point these out.
If there are space issues, you can put these plots in a short supplement.
\end{point}

\reply{
As we discussed in reponse to the other reviewer,
we intentionally chose simulations in this in-between spot;
they are somewhat biologically realistic 
while still retaining a clear way of obtaining the ``right'' answer 
(with regard to admixture proportions and number of discrete populations).
Additional sets of simulations will, in our opinion, make the paper too lengthy and complex;
the applications to real data we hope demonstrate the real-world utility of the method.
We have done ``sanity check'' simulations under the
multivariate-normal model itself,
but as these are far enough from biological reality (e.g., the ``frequencies'' are not between 0 and 1),
we think they'd only make the paper more confusing.
As for the migration rates -- these are given in the text \llname{ll:sim_params},
and we have added an explicit reference to this \llname{ll:sim_params_ref}.
}


\begin{point}{}
    Also, I agree with Reviewer 1 that it would be interesting to see how your method behaves on a biologically plausible, 
idealized, scenario, such as secondary contact with isolation by distance. 
While the ground truth will be blurry for your model, 
if the method infers the ``right clusters" and plausible admixture coefficients 
this would give much credibility to your method - 
showing that it also works when the model does not strictly hold, 
as will always be the case in practice. 
I don't consider this as an essential make-or-break though as the simulation-under-the-model.
\end{point}

\reply{
We realize the coalescent simulations we provide may not satisfy the reviewer's curiosity
regarding isolation by distance,
but note that the tools required to do genome-scale continuous-space simulations 
have only recently become available (in SLiM), long after submission of this paper;
and have not been officially released yet.
We look forward to investigating this in the future.
}

\begin{point}{}
    Issues that should be addressed:
 There is a typo or something missing in Eq. 8 and Eq. 10., 
 there appears an $\ell$ whereas the covariance is already averaged over markers. 
 Do you miss a sum sign here? 
 Please clarify that as this masks an important assumption 
 that is almost certainly violated in most biological realistic scenarios:
The covariance matrices are not the same across markers, 
as drift depends on allele frequency. 
In the extreme case of fixed markers the covariance is always 0! 
In Population Genetics one often models this with a $p(1-p)$ 
prefactor of the covariance matrix or $F_{ST}$ summary statistics. 
Obviously averaging over quite different covariance matrices 
violates the multivariate normal Wishart approximation with 
degrees of freedom equal to L. 
Please elaborate on that issue in the ``technical supplement".
Ringbauer2018 explored a way around this caveat via Fishers-Transform of allele
frequencies or directly modeling F-matrices. (This sentence falls into III).
\end{point}

\reply{Good catch!  Yes, there was a typo (that $\ell$ subscript didn't belong), 
and we have fixed the error. 
Your larger point is correct that the variance of allele frequency differences
is a function of the allele frequency,
so some transformation or normalization of allele frequencies
can help to standardize variances across loci.
We've chosen not to do this for a few reasons:
(a) normalizing by $p(1-p)$ dramatically upweights low-frequency alleles, which can be problematic
(amplifying the \emph{noise} coming from these loci as well as the signal);
(b) the Wishart does not hold anyhow, since loci are not independent (due to linkage)
and have different distributions (depending on frequency and sample size);
and so (c) we are fitting a phenomenological model rather than a mechanistic one
(despite our hopefully compelling justifications).
We have added discussion of this point. \revref
}

\begin{point}{}
    Throughout the manuscript it is implied that Structure-like methods constitutes a subset of yours, 
 corresponding to turning off the spatial covariance component. 
 I have to disagree and think this is misleading: 
 Importantly, Structures also fits allele frequencies for each loci. 
 Thus, a concurrent cline of a few of them can already force the introduction of a new cluster. 
 In stark contrast, ConStruct only uses a single covariance matrix averaged across markers, 
 so will be relatively blind to this behavior of a few markers! 
 It seems important to mention that. 
 In some observed biological scenarios only few markers cause a hybrid zone.
\end{point}

\reply{
    This is a great point.
    However, we're not sure this is how it would work in practice:
    the conStruct model does follow from a model with separate ancestral allele frequencies
    at each locus, in each layer.
    Our model differs in that it combines information across loci into the covariance matrix
    before taking likelihoods,
    while STRUCTURE takes likelihoods first;
    however, it's not obvious how these differ:
    as we note at \llname{ll:wishart},
    if the data were homoskedastic Gaussian, these would be equivalent.
    We're also not sure how well STRUCTURE could identify the effects of a few loci
    above the background of a large number of non-differentiated loci.
    We've reworded the comparison at \revref, and added a caveat to the discussion
    at \llname{ll:admixture_few_loci}.
}

\begin{point}{}
    Put your work in context. 
 While I agree with your assessment that detailed comparisons on simulations is more than enough work for a own paper, 
 it would be nice to put your work into context of methods. 
 In particular discuss methods that can be applied on datasets that are interesting for your method. 
 In particular Geneland and EMS come to mind. 
 The latter will be better to deal with highly heterogeneous landscapes, with varying IBD patterns.
Interestingly, you also compete with Bedassle. 
Since it fits allele frequencies, it likely has higher power to confirm 
hypothesized barriers that aren't detected by this method. 
You could mention something along these lines.
\end{point}

\reply{We have added more text comparing conStruct with Geneland and EEMS and BEDASSLE. \revref}

\begin{point}{}
    In line 97 to 111: The analogy to ``random flipping of allele state" is mildly interesting, 
but does not add much insight. 
You can cut it and start directly with your summary statistic (2) and only mention this analogy in the Supplement/Appendix.
\end{point}

\reply{We have edited that section for clarity and brevity. \revref}

\begin{point}{}
    On multiple occasions you argue that the ``allelic covariance" matrix is
    insensitive to the choice of reference allele.  This is also true for most
    covariance matrices of the style (p1-p, p2-p), or do I miss something?
    The main advantage seems to be that you don't have to estimate mean allele
    frequencies, which is MANY parameters.  You probably have thought quite a
    bit about this step ``down" from Bedasssle, so perhaps share some of your
    views and initial experiments.
\end{point}

\reply{
    True, insensitivity to reference allele is not the motivation for using allelic covariance;
    rather, the motivation comes from insensitivity to the distribution of samples.
    We've tried to make this more clear at \revref{} and at \llname{ll:cov_config}.
}

\begin{point}{}
    In line 72-73, you cite that mainly stepping-stone models gives us some analytical predictions. 
In fact, good analytic approximations are often derived for continuous limits, such as a diffusion model.
You could add some reference for continuous models that incorporate discrete discontinuities and try to merge these two. 
Sometimes, there are analytic approximations, which is obviously relevant: 
Importantly, the landmark work of Nayglaki1988 is missing. 
Morerecently Barton2008 and Ringbauer2018 made some contributions 
for the effects of barriers to gene flow on genetic covariance in a continuous setting. 
They are not directly relevant for this work, but hey could provide useful context.
\end{point}

\reply{Thanks for pointing out these missing and important references.  
We have added them to the manuscript. \revref}

\begin{point}{}
    Your covariance matrix has to be a valid covariance matrix, i.e. positive semidefinite. 
I guess this is why you choose the power of the exponential to be between 0 and 2 
(for other values it isn't), but you never mention that. 
In table 1, some draws from the priors would not produce valid covariance matrices, 
how do you proceed in these cases? 
Do you have implementations that enforce this or are these areas never sampled in practice? 
This issue could mess with the Wishart distribution and matrix inversion if the determinant crosses to negative values.
\end{point}

\reply{Yes, as you say the covariance must be positive semi-definite for us to invert it and calculate the likelihood.
The inference algorithm implemented by STAN automatically rejects proposed matrices that aren't invertible.
While it is possible that this could introduce issues into the mixing of the MCMC, 
in practice we haven't found that concern to be borne out.
We chose not to discuss the bounds on the exponent because the situation is not quite so clear:
although only those exponents will give consistent covariance functions
in continuous, flat, Euclidean space,
the data come from a set of discrete points in a situation where the best notion of distance
may differ substantially from Euclidean.
}

\begin{point}{}
    There seem to be some possible degeneracy issues, 
for instance when $\alpha_d$ goes to 0 (which seems to be the case for some of the inferred layers), 
$\alpha_0$ and $\phi_k$ will becomes indistinguishable.
 You should mention these issues, and if you have dealt with them 
 (or think they are not important, as you are not really interested in estimating these parameters).
\end{point}

\reply{We agree: in practice,
because those parameters can't be easily interpreted in a biological context, 
we treat them more as nuisance parameters and focus on inference of the admixture proportions.
We have plans for a future release that has a more biologically motivated model of IBD (see more below).
We've made a note about this. \revref}
 
\begin{point}{}
    Genetics states ``All articles published by GENETICS must include a 
Data Availability Statement at the end of the Materials and Methods section." 
You don't have such a section at the moment.
For reproducibility of your results, 
you should make at least the covariance matrix and the positions of each deme you used in your analysis available. 
Ideally share all of the genetic data and the scripts used to filter it, including the settings (this is often quite important). 
But if someone is protective of this data, I personally would be fine with omitting it. But this is the editors call to make.
\end{point}

\reply{Thanks for pointing this out.  
We have added a Data Availability Statement, 
and all data analyzed and scripts used to perform the analyses will be archived in Data Dryad.
\revref
}

\begin{point}{}
    Fig. 4 could be relegated to the supplement, it does not show much more really important information as Fig. 2. 
 In particular if you need space.
\end{point}

\reply{We like Fig. 4 as a demonstration of the utility of calculating layer 
contributions as a heuristic of model comparison. 
And, although the information Fig. 4 contains is a little redundant with that of Fig. 2, 
that wouldn't have to be the case, because the $\phi$ parameters for the extra layers 
in the spatial model could be so large that even though ancestry in them was negligible, 
their contributions could still be significant.}

\begin{point}{}
    It would be really helpful if you plot the ground truth admixture coefficients in your K plots (Fig. 2) for $K>2$. 
 It seems you sometimes estimate admixture for populations which have none (also observed in my applications), 
 but not knowing the ground truth this is hard to gauge. 
 You randomly simulated them, so please add this ``ground truth" as an additional plot. 
 I am slightly skeptical about Plot S5 (the admixture coefficients) ? did you do averaging? 
 Having ground truth plots would help to remove my doubts!
\end{point}

\reply{
    We agree, it would be nice to have the plot that is analogous 
    to Figures \ref{simK2_adprop_fit} and \ref{simK3_adprop_fit} in the main text, 
    but we decided that would be too much.
    We don't think we need a ``ground truth'' plot for figure \ref{simK1_pies}, however --
    since the true $K=1$, all true admxiture coefficients are equal to 1.
    We've updated the caption of this figure to better point this out.
    As for Figures \ref{simK2_adprop_fit} and \ref{simK3_adprop_fit},
    we reassure you that there's no funny business:
    those figures show the 99\% credible interval for each population's admixture proportions
    from the spatial conStruct analysis with the appropriate $K$,
    and plotted them against the values used to simulate the data.
    We've added more detail to those captions as well.
}

\begin{point}{}
    Line 386: I think the claim that your model includes a biologically realistic model for isolation by distance is a bit overzealous. 
 Several non-interacting layers of IBD are a bit hard to imagine, 
 or do you have a good example?
 Importantly, your method will infer different clusters when isolation by distance patterns change. 
 So again you run into a problem of inferring a discrete break where there is none. 
 In fact, for most realistic populations one would expect different isolation by distance patterns.
  Could be worth mentioning that caveat, and that in that case EEMS style methods.
\end{point}

\reply{
    Fair enough! We've removed the phrase ``biologically realistic''. \revref{}
    We think these caveats are discussed sufficiently later on,
    at \llname{ll:caveats}.
}

\begin{point}{}
    The headings are a bit off. 
For instance you start with Results and then lay out the model? 
Orient yourself on the excellent structure of the BEDASSLE paper.
 You cite often quite a few works at once (for instance ten in line 60), 
 check if this goes well with the citation style of Genetics).
\end{point}

\reply{These were holdovers from a previous submission format.  
We have edited them for a more logical flow and greater clarity.}

\begin{point}{}
    Suggestions (for future)
 When I run the inference scheme myself, 
 I noticed that mostly only one core on my machine is under full load, while the other remain idle. 
 You could conceive ways to incorporate multi-processing. 
 In particular, if run on a cluster, this could yield huge speed-ups. 
 There seems to be some literature out there in how to do so for the inversion of huge covariance matrices, 
 which seems to be the main bottleneck.
\end{point}

\reply{Parallelization would definitely be helpful.  
Right now, the inference algorithm is implemented in STAN, 
which doesn't have a mechanism for parallelizing a single MCMC chain.
But, as you say, there are algorithms for parallelizing matrix inversions calculations, 
so we might look to porting the inference out of STAN to get greater speedups for future releases.}
 
\begin{point}{}
    You assume a multivariate normal distribution. 
    This implicitly assumes that all higher moments are 0, 
    which is quite the assumption for real data and almost certainly violated. 
    But in some sense, your method fits the covariance matrix 
    - the pattern that it produces it does not matter. 
    This brings me directly to the next point:
    You could explore other ways to fit the covariance matrix. 
    Since typically the model is violated anyways, 
    you won't lose too much (the posterior is no ``real" posterior)
    For instance, fitting all pairwise covariance by for instance least square 
    is not necessarily inferior, but could give you significant speed updates 
    (quadratic, and no cumbersome inversion of the covariance matrix).
    Ringbauer2018 tried such approaches and found 
    that simpler fitting methods often have similar power than more complex ones 
    (whose assumptions are violated anyways), but are much faster.
\end{point}

\reply{This is a nice idea, and one that we have also considered.
We've talked about including a ``fast" conStruct option  
that uses a maximum-likelihood algorithm in a future release, 
and possibly one that uses the TreeMix trick of modeling each cell in the 
sample covariance matrix as a draw from a Normal with a mean given by the 
corresponding cell in the parametric covariance matrix, 
and a standard deviation calculated from by block-boostrapping the genome.
Your suggestion to use least squares would probably be even faster.}

\begin{point}{}
    Right now you have to give the pairwise distance Matrix as parameter to your method, 
and also the sample positions. 
You could easily calculate the former from the latter, 
and would save users some quick but unnecessary preprocessing step. 
I guess in the future you might want to use other distance matrices though.
\end{point}

\reply{Right, it would save users some time for us to calculate pairwise distances for them,
but at the expense of flexibility.
Some users may want to use other distance matrices 
(e.g., distance within a river system, or along a coastline, or around the Tibetan plateau, etc.), 
so we leave it up to them to specify one.}

\begin{point}{}
    In line 569 to line 575: When you describe how to deal with linked markers. 
You don't mention it very explicitly, 
but I think you hint that one can simply do ``block-bootstrap" of whole blocks of genome 
as typically done nowadays for many applications, 
if at least linkage groups are known.
\end{point}

\reply{
    We agree -- that's likely the best way to do it when linkage is known.
    We've added some text about that in the ``Cross-validation" section of the Appendix.
    \revref
}

\begin{point}{}
    The Gamma-Exponential Kernels used here are often considered inferior to Matern-Kernels. 
In practice it likely wont matter much though.
\end{point}

\reply{
    Again, agreed! One of the next updates we plan is to replace the flexible but 
    poorly motivated powered exponential with the form worked out for 
    probability of identity by state in continuous space from Barton, Depaulis, and Etheridge (2000).
}

\begin{point}{}
    I personally really fancy your writing style, 
and it is a golden thread throughout your work.  
But as much as I enjoy learning new words, 
keep in mind many others in Science are non-mother tongue speakers 
(and perhaps less literate native speakers). 
And sometimes it simply feels like you are under contract of an English dictionary company.
Additionally, a more concise and straightforward formulation 
would significantly reduce the length of the manuscript and improve its readability 
- while keeping the information content unchanged. 
\\\\
One example of many, to give you an idea:
``Existing model-based clustering approaches can only describe 
continuous patterns of variation using discrete clusters,
and tend to erroneously describe continuously distributed variation 
with multiple clusters that show spatially autocorrelated cluster membership" (l.82-84)
to 
``Most existing model-based clustering methods only use discrete units. 
Therefore, they often partition continuous variation into spurious clusters. 
(with spatially autocorrelated membership.)"
\\\\
This is merely a suggestion, choice of style is obviously the author's and there is
no ground truth best way.
\end{point}

\reply{First, thank you for the compliment (seriously - ``a golden thread"!).
And, you've pulled out a good example of an overly convoluted sentence;
we have edited it following your excellent suggestion \revref{}.
In this revision, we've tried to be as clear and specific in our writing as possible, 
both in the manuscript, and even more in the R package vignettes. 
We're sure it could still be much better,
but hope it is improved.
% And, while some of the words we choose are perhaps rare in scientific writing, 
% we put great care into our choice of syntax, 
% and we think that the nuances of meaning these odd word-birds lend us merit their inclusion.
% As Mark Twain wrote, ``The difference between the \emph{almost} right word and the right word 
% is really a large matter -- 
% 'tis the difference between the lightning bug and the lightning."
}

\begin{point}{}
    Stress more that an easy-to-use implementation inclusive a manual exists, that is
certainly a strong point! I was impressed by the ease of installation and use, and quality of the manual.
\end{point}

\reply{Good suggestion - we have now indicated that the method is available as a documented R package. \revref}
